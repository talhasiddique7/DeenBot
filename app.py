# Libraries Import
import streamlit as st
import time
from together import Together
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from deep_translator import GoogleTranslator
import os
from dotenv import load_dotenv

# Load API Key
load_dotenv()
TOGETHER_AI_API_KEY = os.getenv("TOGETHER_AI_API_KEY")

# Streamlit UI
st.title("ğŸ“– Ù‚Ø±Ø¢Ù† DeenBot")
st.write("Ù‚Ø±Ø¢Ù† Ú©Û’ Ø¨Ø§Ø±Û’ Ù…ÛŒÚº Ú©ÙˆØ¦ÛŒ Ø¨Ú¾ÛŒ Ø³ÙˆØ§Ù„ Ù¾ÙˆÚ†Ú¾ÛŒÚº!")

# Define Prompt Template to prevent hallucinations
custom_prompt = PromptTemplate(
    input_variables=["context", "query"],
    template="Ø¢Ù¾ Ù‚Ø±Ø¢Ù† Ú©ÛŒ ØªØ´Ø±ÛŒØ­ Ù…ÛŒÚº Ù…ÛØ§Ø±Øª Ø±Ú©Ú¾Ù†Û’ ÙˆØ§Ù„Û’ Ø§ÛŒÚ© AI Ø§Ø³Ø³Ù¹Ù†Ù¹ ÛÛŒÚºÛ” Ø¨Ø±Ø§Û Ú©Ø±Ù… **ØµØ±Ù** Ø¯Ø±Ø¬ Ø°ÛŒÙ„ Ø³ÛŒØ§Ù‚ Ùˆ Ø³Ø¨Ø§Ù‚ Ú©ÛŒ Ø¨Ù†ÛŒØ§Ø¯ Ù¾Ø± Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÚº:\n\n"
             "{context}\n\n"
             "Ø§Ú¯Ø± Ø³ÙˆØ§Ù„ Ù‚Ø±Ø¢Ù† Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ù†Û ÛÙˆØŒ ØªÙˆ Ø¨Ø³ Ú©ÛÛŒÚº: "
             "'Ù…ÛŒÚº ØµØ±Ù Ù‚Ø±Ø¢Ù† Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ø³ÙˆØ§Ù„Ø§Øª Ú©Û’ Ø¬ÙˆØ§Ø¨Ø§Øª Ø¯Û’ Ø³Ú©ØªØ§ ÛÙˆÚºÛ”'\n\n"
             "Ø³ÙˆØ§Ù„: {query}\n"
             "Ø¬ÙˆØ§Ø¨:"
)

@st.cache_resource
def load_faiss():
    """ Load FAISS database with embeddings """
    st.write("ğŸ”„ FAISS ÙˆÛŒÛŒÚ©Ù¹Ø± ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ù„ÙˆÚˆ ÛÙˆ Ø±ÛØ§ ÛÛ’...")
    try:
        embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
        db = FAISS.load_local("vectorstore/quran_faiss", embeddings, allow_dangerous_deserialization=True)
        retriever = db.as_retriever(search_type="similarity", search_kwargs={'k': 3, 'fetch_k': 3})
        st.success("âœ… ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ø³Û’ Ù„ÙˆÚˆ ÛÙˆ Ú¯ÛŒØ§!")
        return retriever
    except Exception as e:
        st.error(f"âŒ FAISS ÚˆÛŒÙ¹Ø§ Ø¨ÛŒØ³ Ù„ÙˆÚˆ Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ: {e}")
        return None

@st.cache_resource
def load_together_ai():
    """ Initialize Together AI API client """
    st.write("ğŸ”„ Together AI Ø³Û’ Ú©Ù†Ú©Ø´Ù† Ù‚Ø§Ø¦Ù… Ú©ÛŒØ§ Ø¬Ø§ Ø±ÛØ§ ÛÛ’...")
    try:
        client = Together(api_key=TOGETHER_AI_API_KEY)
        st.success("âœ… Together AI Ú©Ø§Ù…ÛŒØ§Ø¨ÛŒ Ø³Û’ Ù…ØªØ­Ø±Ú© ÛÙˆ Ú¯ÛŒØ§!")
        return client
    except Exception as e:
        st.error(f"âŒ Together AI Ù…ØªØ­Ø±Ú© Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ: {e}")
        return None

retriever = load_faiss()
together_client = load_together_ai()

def query_together_ai(context, question):
    """ Query the Together AI model with FAISS knowledge only """
    model_name = "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free"
    messages = [{"role": "user", "content": custom_prompt.format(context=context, query=question)}]

    try:
        response = together_client.chat.completions.create(
            model=model_name,
            messages=messages
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"Error: {e}"

if retriever and together_client:
    query = st.text_input("Ø§Ù¾Ù†Ø§ Ø³ÙˆØ§Ù„ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚº:")
    query = GoogleTranslator(source='auto', target='ur').translate(query)

    if st.button("Ù¾ÙˆÚ†Ú¾ÛŒÚº"):
        if query.strip():
            with st.spinner("â³ Ø³ÙˆÚ† Ø±ÛØ§ ÛÛ’..."):
                try:
                    start_time = time.time()  # Start timing
                    
                    # Retrieve relevant documents
                    docs = retriever.get_relevant_documents(query)
                    print(docs)
                    context = "\n".join([doc.page_content for doc in docs]) if docs else "Ú©ÙˆØ¦ÛŒ Ù…ØªØ¹Ù„Ù‚Û Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†ÛÛŒÚº Ù…Ù„ÛŒÛ”"

                    # Ensure the model doesn't make up answers
                    if context == "Ú©ÙˆØ¦ÛŒ Ù…ØªØ¹Ù„Ù‚Û Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†ÛÛŒÚº Ù…Ù„ÛŒÛ”":
                        response_text = "âš ï¸ Ù…ÛŒÚº ØµØ±Ù Ù‚Ø±Ø¢Ù† Ø³Û’ Ù…ØªØ¹Ù„Ù‚ Ø³ÙˆØ§Ù„Ø§Øª Ú©Û’ Ø¬ÙˆØ§Ø¨Ø§Øª Ø¯Û’ Ø³Ú©ØªØ§ ÛÙˆÚºÛ”"
                    else:
                        response_text = query_together_ai(context, query)

                    end_time = time.time()  # End timing
                    response_time = round(end_time - start_time, 2)  # Calculate response time

                    # Display response
                    st.subheader("**Ø¬ÙˆØ§Ø¨:**")
                    st.write(response_text.strip())
                    st.write(f"â± Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÙ†Û’ Ú©Ø§ ÙˆÙ‚Øª: {response_time} Ø³ÛŒÚ©Ù†Úˆ")

                    # Display sources
                    if docs:
                        st.subheader("ğŸ“Œ Ù…Ø§Ø®Ø°:")
                        for i, doc in enumerate(docs, 1):
                            source = doc.metadata.get('source', 'Ù†Ø§Ù…Ø¹Ù„ÙˆÙ… Ù…Ø§Ø®Ø°')
                            st.write(f"{i}. {source if source.strip() else 'Ù…Ø§Ø®Ø° Ø¯Ø³ØªÛŒØ§Ø¨ Ù†ÛÛŒÚº'}")
                    else:
                          st.info("Ú©ÙˆØ¦ÛŒ Ù…ØªØ¹Ù„Ù‚Û Ù…Ø§Ø®Ø° Ù†ÛÛŒÚº Ù…Ù„Ø§Û”")
                except Exception as e:
                    st.error(f"âŒ Ø³ÙˆØ§Ù„ Ù¾Ø± Ú©Ø§Ø±Ø±ÙˆØ§Ø¦ÛŒ Ú©Ø±Ù†Û’ Ù…ÛŒÚº Ø®Ø±Ø§Ø¨ÛŒ: {e}")
        else:
            st.warning("âš ï¸ Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø§ÛŒÚ© Ø¯Ø±Ø³Øª Ø³ÙˆØ§Ù„ Ø¯Ø±Ø¬ Ú©Ø±ÛŒÚºÛ”")
